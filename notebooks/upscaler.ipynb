{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GoCel_eLoCU"
      },
      "source": [
        "# Upscaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import glob\n",
        "import PIL\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLqw8UVOLpBj"
      },
      "source": [
        "The pages (.png) are in `/pages`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uMHfAs_ELhNt"
      },
      "outputs": [],
      "source": [
        "def get_id(n):\n",
        "    charset = \"123456789abcdef\"\n",
        "    return \"\".join([random.choice(charset) for _ in range(n)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kFFeIq2Luu8"
      },
      "source": [
        "We extract high-quality 512×512px training images from each page and save them in `/training`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EpBBdxEdLsgi"
      },
      "outputs": [],
      "source": [
        "output_dir = \"/content/training\"\n",
        "\n",
        "tile_size = 256\n",
        "stride = 256\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "files = glob.glob(\"/content/pages/*.png\")[:15]\n",
        "\n",
        "for filename in files:\n",
        "    with PIL.Image.open(filename) as input_image:\n",
        "        # Compute the number of tiles\n",
        "        width, height = input_image.size\n",
        "        tiles_w = int((width - tile_size) / stride) + 1\n",
        "        tiles_h = int((height - tile_size) / stride) + 1\n",
        "\n",
        "        # Extract each tile and save to disk\n",
        "        for i in range(tiles_w):\n",
        "            for j in range(tiles_h):\n",
        "                x = i * stride\n",
        "                y = j * stride\n",
        "                x_end = x + tile_size\n",
        "                y_end = y + tile_size\n",
        "\n",
        "                # Extract the patch from the input image\n",
        "                tile = input_image.crop((x, y, x_end, y_end))\n",
        "\n",
        "                # Save the patch as PNG in output_dir\n",
        "                output_path = os.path.join(output_dir, f\"{get_id(16)}.png\")\n",
        "                tile.save(output_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn8YuKEDL4E2"
      },
      "source": [
        "We create train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N-qWSeHKL_zK"
      },
      "outputs": [],
      "source": [
        "! mkdir -p images/train\n",
        "! mkdir images/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FUzJB-3fLyn0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "img_folder = \"training\"\n",
        "\n",
        "train_folder = \"images/train\"\n",
        "test_folder = \"images/test\"\n",
        "\n",
        "train_ratio = 0.75\n",
        "test_ratio = 0.25\n",
        "\n",
        "files = glob.glob(img_folder + \"/*.png\")\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(files)\n",
        "\n",
        "num_train = int(len(files) * train_ratio)\n",
        "num_test = int(len(files) * test_ratio)\n",
        "\n",
        "# Move training files\n",
        "for img_name in files[:num_train]:\n",
        "    destination = os.path.join(train_folder, img_name.split(\"/\")[1])\n",
        "    shutil.move(img_name, destination)\n",
        "\n",
        "# Move test files\n",
        "for img_name in files[num_train:]:\n",
        "    destination = os.path.join(test_folder, img_name.split(\"/\")[1])\n",
        "    shutil.move(img_name, destination)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSftPVr7NL29"
      },
      "source": [
        "## Training the upscaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW-uSdb0OgCt",
        "outputId": "416e5bd3-60b9-4bda-aa25-94765ccd89ba"
      },
      "outputs": [],
      "source": [
        "crop_size = 512\n",
        "upscale_factor = 2\n",
        "input_size = crop_size // upscale_factor\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "def process_input(input, input_size):\n",
        "    # Convert to YCbCr, and resize to input_size × input_size\n",
        "    input = tf.image.rgb_to_yuv(input)\n",
        "    last_dimension_axis = len(input.shape) - 1\n",
        "    y, u, v = tf.split(input, 3, axis=last_dimension_axis)\n",
        "    return tf.image.resize(y, [input_size, input_size], method=\"area\")\n",
        "\n",
        "\n",
        "def process_target(input):\n",
        "    # Convert to YCbCr, and extract the Y channel\n",
        "    input = tf.image.rgb_to_yuv(input)\n",
        "    last_dimension_axis = len(input.shape) - 1\n",
        "    y, u, v = tf.split(input, 3, axis=last_dimension_axis)\n",
        "    return y\n",
        "\n",
        "\n",
        "def create_dataset(root_dir, batch_size, crop_size, validation_split=0.3, seed=42):\n",
        "    scaler = keras.Sequential(\n",
        "        [\n",
        "            layers.experimental.preprocessing.Rescaling(\n",
        "                1.0 / 255, input_shape=(None, None, 3)\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    dataset_options = dict(\n",
        "        batch_size=batch_size,\n",
        "        image_size=(crop_size, crop_size),\n",
        "        validation_split=validation_split,\n",
        "        seed=seed,\n",
        "        label_mode=None,\n",
        "    )\n",
        "\n",
        "    train_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "        root_dir, subset=\"training\", **dataset_options\n",
        "    )\n",
        "\n",
        "    valid_ds = keras.preprocessing.image_dataset_from_directory(\n",
        "        root_dir, subset=\"validation\", **dataset_options\n",
        "    )\n",
        "\n",
        "    # Scale images\n",
        "    train_ds = train_ds.map(lambda x: (scaler(x),))\n",
        "    valid_ds = valid_ds.map(lambda x: (scaler(x),))\n",
        "\n",
        "    train_ds = train_ds.map(lambda x: (process_input(x, input_size), process_target(x)))\n",
        "    train_ds = train_ds.prefetch(buffer_size=32)\n",
        "\n",
        "    valid_ds = valid_ds.map(lambda x: (process_input(x, input_size), process_target(x)))\n",
        "    valid_ds = valid_ds.prefetch(buffer_size=32)\n",
        "\n",
        "    return train_ds, valid_ds\n",
        "\n",
        "\n",
        "train_ds, valid_ds = create_dataset(\"images/train\", batch_size, crop_size)\n",
        "test_img_paths = glob.glob(test_folder + \"/*.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KGuI_dn9RBnx"
      },
      "outputs": [],
      "source": [
        "def get_lr(img, upscale_factor):\n",
        "    # Resize image to width/upscale_factor × height/upscale_factor\n",
        "    return img.resize(\n",
        "        (img.size[0] // upscale_factor, img.size[1] // upscale_factor),\n",
        "        PIL.Image.BICUBIC,\n",
        "    )\n",
        "\n",
        "\n",
        "def upscale_image(model, img):\n",
        "    # Convert into YCbCr\n",
        "    ycbcr = img.convert(\"YCbCr\")\n",
        "\n",
        "    # Split into separate channels\n",
        "    y, cb, cr = ycbcr.split()\n",
        "\n",
        "    # Upscale the Y channel\n",
        "    y = img_to_array(y)\n",
        "    y = y.astype(\"float32\") / 255.0\n",
        "\n",
        "    input = np.expand_dims(y, axis=0)\n",
        "    out = model.predict(input)\n",
        "\n",
        "    out_img_y = out[0]\n",
        "    out_img_y *= 255.0\n",
        "\n",
        "    # Reshape Y channel\n",
        "    out_img_y = out_img_y.clip(0, 255)\n",
        "    out_img_y = out_img_y.reshape((np.shape(out_img_y)[0], np.shape(out_img_y)[1]))\n",
        "    out_img_y = PIL.Image.fromarray(np.uint8(out_img_y), mode=\"L\")\n",
        "\n",
        "    # Bicubic upscaling for Cb channel\n",
        "    out_img_cb = cb.resize(out_img_y.size, PIL.Image.BICUBIC)\n",
        "\n",
        "    # Bicubic upscaling for Cr channel\n",
        "    out_img_cr = cr.resize(out_img_y.size, PIL.Image.BICUBIC)\n",
        "\n",
        "    # Combine channels into an image, convert to RGB\n",
        "    out_img = PIL.Image.merge(\"YCbCr\", (out_img_y, out_img_cb, out_img_cr)).convert(\n",
        "        \"RGB\"\n",
        "    )\n",
        "\n",
        "    return out_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uhX1BdMuRMBr"
      },
      "outputs": [],
      "source": [
        "class ESPCNCallback(keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.test_img = get_lr(load_img(test_img_paths[0]), upscale_factor)\n",
        "\n",
        "    # Store PSNR value in each epoch.\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.psnr = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(\"Mean PSNR for epoch: %.2f\" % (np.mean(self.psnr)))\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "        self.psnr.append(10 * math.log10(1 / logs[\"loss\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD0Ypm6DRPlH",
        "outputId": "525442b9-7d70-4289-9792-d93a0bc2c352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None, None, 1)]   0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, None, None, 64)    1664      \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, None, None, 64)    36928     \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, None, None, 32)    18464     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, None, None, 4)     1156      \n",
            "                                                                 \n",
            " tf.nn.depth_to_space_1 (TFO  (None, None, None, 1)    0         \n",
            " pLambda)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58,212\n",
            "Trainable params: 58,212\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "early_stopping_callback = keras.callbacks.EarlyStopping(monitor=\"loss\", patience=10)\n",
        "\n",
        "checkpoint_filepath = \"/checkpoint\"\n",
        "\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor=\"loss\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True,\n",
        ")\n",
        "\n",
        "conv_args = {\n",
        "    \"activation\": \"relu\",\n",
        "    \"kernel_initializer\": \"Orthogonal\",\n",
        "    \"padding\": \"same\",\n",
        "}\n",
        "\n",
        "inputs = keras.Input(shape=(None, None, 1))\n",
        "x = layers.Conv2D(64, 5, **conv_args)(inputs)\n",
        "x = layers.Conv2D(64, 3, **conv_args)(x)\n",
        "x = layers.Conv2D(32, 3, **conv_args)(x)\n",
        "x = layers.Conv2D(upscale_factor**2, 3, **conv_args)(x)\n",
        "outputs = tf.nn.depth_to_space(x, upscale_factor)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZXxZ9-hRQ0v"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=keras.losses.MeanSquaredError(),\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=valid_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=[ESPCNCallback(), early_stopping_callback, model_checkpoint_callback],\n",
        "    verbose=2,\n",
        ")\n",
        "\n",
        "model.load_weights(checkpoint_filepath)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
