{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoiser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes you have training images in `/training`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder, size=(256, 256)):\n",
    "    images = []\n",
    "    files = os.listdir(folder)\n",
    "    random.shuffle(files)\n",
    "    for file in files:\n",
    "        img_path = os.path.join(folder, file)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, size)\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "def generate_jpeg_images(images, quality=60):\n",
    "    jpeg_images = []\n",
    "    for img in images:\n",
    "        _, encoded_img = cv2.imencode(\".jpg\", img, [cv2.IMWRITE_JPEG_QUALITY, quality])\n",
    "        decoded_img = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR)\n",
    "        jpeg_images.append(decoded_img)\n",
    "    return np.array(jpeg_images)\n",
    "\n",
    "\n",
    "folder = \"/content/training\"\n",
    "source_images = load_images(folder)\n",
    "jpeg_images = generate_jpeg_images(source_images)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    jpeg_images, source_images, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "y_train = y_train.astype(\"float32\") / 255.0\n",
    "y_test = y_test.astype(\"float32\") / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/images/train\"\n",
    "batch_size = 16\n",
    "data_generator = ImageDataGenerator(folder, batch_size)\n",
    "\n",
    "X_train = data_generator\n",
    "y_train = None\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "test_files = os.listdir(\"/images/test\")\n",
    "for file in test_files:\n",
    "    img_path = os.path.join(\"/images/test\", file)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    X_test.append(img / 255.0)\n",
    "\n",
    "    _, encoded_img = cv2.imencode(\n",
    "        \".jpg\", img, [cv2.IMWRITE_JPEG_QUALITY, random.randint(20, 80)]\n",
    "    )\n",
    "    decoded_img = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR)\n",
    "    y_test.append(decoded_img / 255.0)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size=(256, 256, 3)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    conv1 = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv_last = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv_last = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(conv_last)\n",
    "    up_last = UpSampling2D(size=(2, 2))(conv_last)\n",
    "    merge_last = concatenate([conv1, up_last], axis=3)\n",
    "    conv_last = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(merge_last)\n",
    "    conv_last = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(conv_last)\n",
    "\n",
    "    conv_out = Conv2D(3, 1, activation=\"linear\")(\n",
    "        conv_last\n",
    "    )\n",
    "\n",
    "    return Model(inputs=inputs, outputs=conv_out)\n",
    "\n",
    "\n",
    "model = unet_model()\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mae\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    \"denoiser-{epoch:02d}.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=16,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[checkpoint],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"denoiser.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
